{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 5819 Project -- Using BRF on Imbalanced Data"
      ],
      "metadata": {
        "id": "YFKy7xrOOv1c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Libraries"
      ],
      "metadata": {
        "id": "EW9_HTI9O1yI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xklauWvDOu82"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.utils import resample\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Dataset from Google Drive\n",
        "\n",
        "\n",
        "[link to dataset](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud?resource=download)"
      ],
      "metadata": {
        "id": "djbVvOBnO6Ft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "file_path = '/content/drive/MyDrive/5819 Project/creditcard.csv'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtOMKxSaOvRn",
        "outputId": "b8a7bba8-23bd-42b1-bd7f-41600fd5e768"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dataset is stored in an Excel file\n",
        "\n",
        "We will convert it to a pandas DataFrame in order to analyze & manipulate the data"
      ],
      "metadata": {
        "id": "GkFacM_4PfGu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# store the entire data set\n",
        "df = pd.read_csv(file_path)\n",
        "print(f\"Number of rows: {df.shape[0]}\")\n",
        "print(f\"Number of columns: {df.shape[1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJ0_UVS1PaYI",
        "outputId": "87308b7c-7988-4b0b-e9d1-879502534c00"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows: 284807\n",
            "Number of columns: 31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize:\n",
        "- Design Matrix X (the features)\n",
        "- Label Vector, y (ground truth)"
      ],
      "metadata": {
        "id": "0oi1g7_NS3RZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop('Class', axis=1)\n",
        "y = df['Class']"
      ],
      "metadata": {
        "id": "RMFSIRzQQLeZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10-Fold CV -- following methodology from paper\n",
        "- StratifiedKFlod --> keeps class ratio the same"
      ],
      "metadata": {
        "id": "8uRFG2kMZ8fu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)"
      ],
      "metadata": {
        "id": "AbLHGUeWZ-Iq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BRF Algorithm (according to the paper):\n",
        "1. for each iteration in RF, draw bootstrap sample from minority class. Randomly draw the same number of cases, with replacement, from the majority class\n",
        "2. Induce a classification tree from the data to maximum size, without pruning. The tree is induced with the CART algorithm, with the following modification: At each node, instead of searching through all variables for the optimal split, only search through a set of mtry randomly selected variables\n",
        "3. Repeat the two steps above for the number of times desired. Aggregate the predictions of the ensemble and make the final prediction\n"
      ],
      "metadata": {
        "id": "BKM1cYOtbqBS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize number of trees to create [STEP 3]\n",
        "  # scikit=learn default is 100 (paper does not specify how many they used)\n",
        "num_trees = 100\n",
        "\n",
        "# initialize list to store all 10 reports (precision, recall, F1-score, support for each fold)\n",
        "perf_metrics = []\n",
        "\n",
        "# STEP 3 --> repeat steps 1 & 2 for the number of times desired (100)\n",
        "for fold, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n",
        "    # for each fold, split the data into 10 equal parts\n",
        "      # train on 9 of the 10 folds\n",
        "      # test on 1 of the 10 folds\n",
        "      # repeat 10 times (st. every data point is used for testing exactly once)\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    # we train with the labels -- init labeled training dataframe\n",
        "    train_data = pd.concat([X_train, y_train], axis=1)\n",
        "    brf_trees = []\n",
        "\n",
        "    for _ in range(num_trees):\n",
        "\n",
        "        # preprocessing step: in order to create the bootstrap samples from majority & minority class\n",
        "          # we can create a df for majority & minority by using the class attribute\n",
        "        df_minority = train_data[train_data['Class'] == 1]\n",
        "        df_majority = train_data[train_data['Class'] == 0]\n",
        "\n",
        "        # STEP 1: for each iteration in RF, draw bootstrap sample from minority class\n",
        "          # then same number of cases from majority class --> n_samples=len(df_minority)\n",
        "          # with replacement --> replace=True\n",
        "        boot_min = resample(df_minority, replace=True, n_samples=len(df_minority), random_state=np.random.randint(10000))\n",
        "        boot_maj = resample(df_majority, replace=True, n_samples=len(df_minority), random_state=np.random.randint(10000))\n",
        "\n",
        "        # concatenate the bootstraps --> creating an artificially balanced dataset (via down-sampling majority class)\n",
        "        bootstrap_sample = pd.concat([boot_min, boot_maj])\n",
        "\n",
        "        # initialize the design matrix and label column vector for this sample\n",
        "        X_boot = bootstrap_sample.drop('Class', axis=1)\n",
        "        y_boot = bootstrap_sample['Class']\n",
        "\n",
        "        # STEP 2 --> create classification tree from data to maximum size, without pruning\n",
        "          # at each node, only search through mtry random variables for optimal split\n",
        "          # [we use mtry = sqrt(p) --> default convention from Breiman's original RF paper (2001)]\n",
        "        tree = DecisionTreeClassifier(\n",
        "            max_features='sqrt', random_state=np.random.randint(10000)\n",
        "        )\n",
        "        tree.fit(X_boot, y_boot)\n",
        "        brf_trees.append(tree)\n",
        "\n",
        "    # -- AT THIS POINT --\n",
        "      # we have TRAINED the forest using the training dataset for this fold\n",
        "      # now, we will run the TEST set through the forest and make predictions\n",
        "\n",
        "    # preds --> model predictions for TEST set [there will be 100 predictions]\n",
        "    preds = np.array([tree.predict(X_test) for tree in brf_trees])\n",
        "\n",
        "    # y_pred --> mean prediction across all trees, then round to nearest label\n",
        "    y_pred = np.round(np.mean(preds, axis=0))\n",
        "\n",
        "    # for each fold, we will compute the performance metrics\n",
        "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "\n",
        "    # compute metrics in accordance with the paper\n",
        "    acc_pos = tp / (tp + fn)  # [ Acc⁺ = Recall ]\n",
        "    acc_neg = tn / (tn + fp)  # [ Acc⁻ = Specificity ]\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f_measure = 2 * (precision * recall) / (precision + recall)\n",
        "    g_mean = (acc_pos * acc_neg) ** 0.5\n",
        "    weighted_accuracy = 0.5 * (acc_pos + acc_neg)\n",
        "\n",
        "    # append the metrics for each fold to performance metrics list\n",
        "    perf_metrics.append({\n",
        "        'acc_pos': acc_pos,\n",
        "        'acc_neg': acc_neg,\n",
        "        'precision': precision,\n",
        "        'f1': f_measure,\n",
        "        'g_mean': g_mean,\n",
        "        'weighted_accuracy': weighted_accuracy\n",
        "    })"
      ],
      "metadata": {
        "id": "qqzyogsAaSrR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have measures for the performance metrics across all 10 folds, we average them and print the results as a percentage (in accordance with the paper)"
      ],
      "metadata": {
        "id": "hEYpZHMooXZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def avg(metric):\n",
        "    return np.mean([m[metric] for m in perf_metrics])\n",
        "\n",
        "print(\"BRF Metrics \\n----------------------------\")\n",
        "print(f\"Acc⁺ (Recall):        {avg('acc_pos')*100:.2f}%\")\n",
        "print(f\"Acc⁻ (Specificity):   {avg('acc_neg')*100:.2f}%\")\n",
        "print(f\"Precision:            {avg('precision')*100:.2f}%\")\n",
        "print(f\"F1-Score:             {avg('f1')*100:.2f}%\")\n",
        "print(f\"G-Mean:               {avg('g_mean')*100:.2f}%\")\n",
        "print(f\"Weighted Accuracy:    {avg('weighted_accuracy')*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdYS8xSRxpb5",
        "outputId": "b36b3c3d-f6f8-411b-84eb-943db66a2cf7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BRF Metrics \n",
            "----------------------------\n",
            "Acc⁺ (Recall):        89.02%\n",
            "Acc⁻ (Specificity):   99.07%\n",
            "Precision:            14.25%\n",
            "F1-Score:             24.54%\n",
            "G-Mean:               93.89%\n",
            "Weighted Accuracy:    94.04%\n"
          ]
        }
      ]
    }
  ]
}